{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/schmid/Text2Head/NPHM\")\n",
    "\n",
    "import torch\n",
    "from torch.optim import Adam\n",
    "from utils.pipeline import forward, get_latent_mean_std, get_latent_from_text\n",
    "import optuna\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook serves to find the best hyperparameters for the optimization.\n",
    "Important:\n",
    "- to make different runs comparable, we always start from lat_mean\n",
    "- for the model to be able to yield good results for varying prompts, we use 3 prompts from different categories (gender, ethnicity, hairstyle) for the hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_mean, lat_std = get_latent_mean_std()\n",
    "\n",
    "hparams = {\n",
    "        'resolution': 120,\n",
    "        'n_iterations': 50,\n",
    "        'optimizer_lr': 0.02,\n",
    "        'lr_scheduler_factor': 0.1,\n",
    "        'lr_scheduler_patience': 2,\n",
    "        'lr_scheduler_min_lr': 1e-5\n",
    "    }\n",
    "\n",
    "prompts = []\n",
    "prompts.append('A woman')\n",
    "prompts.append('An Asian person')\n",
    "prompts.append('A person with beard')\n",
    "\n",
    "def latent_optimization(hparams):\n",
    "    all_CLIP_scores = []\n",
    "    for prompt in prompts:\n",
    "        _, best_score, _ = get_latent_from_text(prompt, hparams, init_lat=lat_mean)\n",
    "        all_CLIP_scores.append(best_score)\n",
    "\n",
    "    all_CLIP_scores_tensor = torch.stack(all_CLIP_scores)\n",
    "    print(all_CLIP_scores_tensor)\n",
    "    # Calculate the average\n",
    "    average_score = torch.mean(all_CLIP_scores_tensor)\n",
    "\n",
    "    return average_score\n",
    "\n",
    "def objective(trial):\n",
    "\n",
    "    search_space = {\n",
    "        'resolution': 120,\n",
    "        'n_iterations': trial.suggest_categorical('n_iterations', [40, 50, 60, 70]),\n",
    "        'optimizer_lr': trial.suggest_float('optimizer_lr', 1e-4, 1e-2, log=True),\n",
    "        'lr_scheduler_factor': trial.suggest_float('lr_scheduler_factor', 0.1, 0.9),\n",
    "        'lr_scheduler_patience': trial.suggest_int('lr_scheduler_patience', 2, 5),\n",
    "        'lr_scheduler_min_lr': trial.suggest_float('lr_scheduler_minlr', 1e-5, 1e-4, log=True),\n",
    "    }\n",
    "\n",
    "    hparams.update(search_space)\n",
    "\n",
    "    return latent_optimization(hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-07 16:29:32,364] Using an existing study with name 'optim_hparams' instead of creating a new one.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]\n",
      "[W 2023-12-07 16:29:32,530] Trial 1 failed with parameters: {'n_iterations': 50, 'optimizer_lr': 0.0037586281146446444, 'lr_scheduler_factor': 0.22516937725024164, 'lr_scheduler_patience': 2, 'lr_scheduler_minlr': 1.5171601286511644e-05} because of the following error: OutOfMemoryError('CUDA out of memory. Tried to allocate 440.00 MiB (GPU 0; 10.91 GiB total capacity; 8.29 GiB already allocated; 95.44 MiB free; 8.57 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF').\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/schmid/miniconda3/envs/nphm/lib/python3.9/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_66556/3085136350.py\", line 43, in objective\n",
      "    return latent_optimization(hparams)\n",
      "  File \"/tmp/ipykernel_66556/3085136350.py\", line 20, in latent_optimization\n",
      "    _, best_score, _ = get_latent_from_text(prompt, hparams, init_lat=lat_mean)\n",
      "  File \"/home/schmid/Text2Head/utils/pipeline.py\", line 141, in get_latent_from_text\n",
      "    best_score = torch.tensor([0])\n",
      "  File \"/home/schmid/Text2Head/utils/pipeline.py\", line 65, in forward\n",
      "    def forward(lat_rep, prompt, camera_params, phong_params, light_params):\n",
      "  File \"/home/schmid/Text2Head/utils/render.py\", line 201, in render\n",
      "    hit_positions, hit_mask = two_phase_tracing(sdf, camera_position, directions, camera_params['max_ray_length'])\n",
      "  File \"/home/schmid/Text2Head/utils/render.py\", line 140, in two_phase_tracing\n",
      "    hits_1, hit_mask_1, t_1 = acc_sphere_trace(sdf, camera_position, norm_directions, max_length,\n",
      "  File \"/home/schmid/Text2Head/utils/render.py\", line 117, in acc_sphere_trace\n",
      "    r_next[mask] = sdf(positions[mask] + ((t[mask] + d_curr[mask]) * norm_directions[mask].T).T)\n",
      "  File \"/home/schmid/Text2Head/utils/render.py\", line 168, in sdf\n",
      "    distance = model(nphm_input.to(device), lat_rep_in.to(device), None)[0].to(\"cpu\")\n",
      "  File \"/home/schmid/miniconda3/envs/nphm/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1190, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/schmid/Text2Head/NPHM/src/NPHM/models/EnsembledDeepSDF.py\", line 257, in forward\n",
      "    sdf_pred = self.ensembled_deep_sdf(coords, cond)\n",
      "  File \"/home/schmid/miniconda3/envs/nphm/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1190, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/schmid/Text2Head/NPHM/src/NPHM/models/EnsembledDeepSDF.py\", line 121, in forward\n",
      "    x = self.activation(x)\n",
      "  File \"/home/schmid/miniconda3/envs/nphm/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1190, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/schmid/miniconda3/envs/nphm/lib/python3.9/site-packages/torch/nn/modules/activation.py\", line 841, in forward\n",
      "    return F.softplus(input, self.beta, self.threshold)\n",
      "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 440.00 MiB (GPU 0; 10.91 GiB total capacity; 8.29 GiB already allocated; 95.44 MiB free; 8.57 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
      "[W 2023-12-07 16:29:32,531] Trial 1 failed with value None.\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 440.00 MiB (GPU 0; 10.91 GiB total capacity; 8.29 GiB already allocated; 95.44 MiB free; 8.57 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m/home/schmid/Text2Head/notebooks/hparamtuning.ipynb Cell 4\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bniessnerlab/home/schmid/Text2Head/notebooks/hparamtuning.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bniessnerlab/home/schmid/Text2Head/notebooks/hparamtuning.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m     study \u001b[39m=\u001b[39m optuna\u001b[39m.\u001b[39mcreate_study(storage\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39msqlite:///../optuna_study_hparams.db\u001b[39m\u001b[39m\"\u001b[39m, study_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39moptim_hparams\u001b[39m\u001b[39m\"\u001b[39m, direction\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmaximize\u001b[39m\u001b[39m'\u001b[39m, load_if_exists\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bniessnerlab/home/schmid/Text2Head/notebooks/hparamtuning.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m     study\u001b[39m.\u001b[39;49moptimize(objective, n_trials\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bniessnerlab/home/schmid/Text2Head/notebooks/hparamtuning.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m     best_params \u001b[39m=\u001b[39m study\u001b[39m.\u001b[39mbest_params\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bniessnerlab/home/schmid/Text2Head/notebooks/hparamtuning.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39mprint\u001b[39m(best_params)\n",
      "File \u001b[0;32m~/miniconda3/envs/nphm/lib/python3.9/site-packages/optuna/study/study.py:451\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39moptimize\u001b[39m(\n\u001b[1;32m    349\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    350\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    357\u001b[0m     show_progress_bar: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    358\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    359\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    360\u001b[0m \n\u001b[1;32m    361\u001b[0m \u001b[39m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[39m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    450\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 451\u001b[0m     _optimize(\n\u001b[1;32m    452\u001b[0m         study\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m    453\u001b[0m         func\u001b[39m=\u001b[39;49mfunc,\n\u001b[1;32m    454\u001b[0m         n_trials\u001b[39m=\u001b[39;49mn_trials,\n\u001b[1;32m    455\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    456\u001b[0m         n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[1;32m    457\u001b[0m         catch\u001b[39m=\u001b[39;49m\u001b[39mtuple\u001b[39;49m(catch) \u001b[39mif\u001b[39;49;00m \u001b[39misinstance\u001b[39;49m(catch, Iterable) \u001b[39melse\u001b[39;49;00m (catch,),\n\u001b[1;32m    458\u001b[0m         callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m    459\u001b[0m         gc_after_trial\u001b[39m=\u001b[39;49mgc_after_trial,\n\u001b[1;32m    460\u001b[0m         show_progress_bar\u001b[39m=\u001b[39;49mshow_progress_bar,\n\u001b[1;32m    461\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/nphm/lib/python3.9/site-packages/optuna/study/_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     65\u001b[0m     \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m---> 66\u001b[0m         _optimize_sequential(\n\u001b[1;32m     67\u001b[0m             study,\n\u001b[1;32m     68\u001b[0m             func,\n\u001b[1;32m     69\u001b[0m             n_trials,\n\u001b[1;32m     70\u001b[0m             timeout,\n\u001b[1;32m     71\u001b[0m             catch,\n\u001b[1;32m     72\u001b[0m             callbacks,\n\u001b[1;32m     73\u001b[0m             gc_after_trial,\n\u001b[1;32m     74\u001b[0m             reseed_sampler_rng\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m     75\u001b[0m             time_start\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m     76\u001b[0m             progress_bar\u001b[39m=\u001b[39;49mprogress_bar,\n\u001b[1;32m     77\u001b[0m         )\n\u001b[1;32m     78\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     79\u001b[0m         \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/nphm/lib/python3.9/site-packages/optuna/study/_optimize.py:163\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 163\u001b[0m     frozen_trial \u001b[39m=\u001b[39m _run_trial(study, func, catch)\n\u001b[1;32m    164\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    165\u001b[0m     \u001b[39m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[39m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    167\u001b[0m     \u001b[39m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    168\u001b[0m     \u001b[39m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    169\u001b[0m     \u001b[39mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m~/miniconda3/envs/nphm/lib/python3.9/site-packages/optuna/study/_optimize.py:251\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mFalse\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39mShould not reach.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    246\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    247\u001b[0m     frozen_trial\u001b[39m.\u001b[39mstate \u001b[39m==\u001b[39m TrialState\u001b[39m.\u001b[39mFAIL\n\u001b[1;32m    248\u001b[0m     \u001b[39mand\u001b[39;00m func_err \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    249\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    250\u001b[0m ):\n\u001b[0;32m--> 251\u001b[0m     \u001b[39mraise\u001b[39;00m func_err\n\u001b[1;32m    252\u001b[0m \u001b[39mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m~/miniconda3/envs/nphm/lib/python3.9/site-packages/optuna/study/_optimize.py:200\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[39mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[39m.\u001b[39m_trial_id, study\u001b[39m.\u001b[39m_storage):\n\u001b[1;32m    199\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 200\u001b[0m         value_or_values \u001b[39m=\u001b[39m func(trial)\n\u001b[1;32m    201\u001b[0m     \u001b[39mexcept\u001b[39;00m exceptions\u001b[39m.\u001b[39mTrialPruned \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    202\u001b[0m         \u001b[39m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    203\u001b[0m         state \u001b[39m=\u001b[39m TrialState\u001b[39m.\u001b[39mPRUNED\n",
      "\u001b[1;32m/home/schmid/Text2Head/notebooks/hparamtuning.ipynb Cell 4\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bniessnerlab/home/schmid/Text2Head/notebooks/hparamtuning.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=31'>32</a>\u001b[0m search_space \u001b[39m=\u001b[39m {\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bniessnerlab/home/schmid/Text2Head/notebooks/hparamtuning.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=32'>33</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mresolution\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m120\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bniessnerlab/home/schmid/Text2Head/notebooks/hparamtuning.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=33'>34</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mn_iterations\u001b[39m\u001b[39m'\u001b[39m: trial\u001b[39m.\u001b[39msuggest_categorical(\u001b[39m'\u001b[39m\u001b[39mn_iterations\u001b[39m\u001b[39m'\u001b[39m, [\u001b[39m40\u001b[39m, \u001b[39m50\u001b[39m, \u001b[39m60\u001b[39m, \u001b[39m70\u001b[39m]),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bniessnerlab/home/schmid/Text2Head/notebooks/hparamtuning.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=37'>38</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mlr_scheduler_min_lr\u001b[39m\u001b[39m'\u001b[39m: trial\u001b[39m.\u001b[39msuggest_float(\u001b[39m'\u001b[39m\u001b[39mlr_scheduler_minlr\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m1e-5\u001b[39m, \u001b[39m1e-4\u001b[39m, log\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m),\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bniessnerlab/home/schmid/Text2Head/notebooks/hparamtuning.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=38'>39</a>\u001b[0m }\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bniessnerlab/home/schmid/Text2Head/notebooks/hparamtuning.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=40'>41</a>\u001b[0m hparams\u001b[39m.\u001b[39mupdate(search_space)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bniessnerlab/home/schmid/Text2Head/notebooks/hparamtuning.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=42'>43</a>\u001b[0m \u001b[39mreturn\u001b[39;00m latent_optimization(hparams)\n",
      "\u001b[1;32m/home/schmid/Text2Head/notebooks/hparamtuning.ipynb Cell 4\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bniessnerlab/home/schmid/Text2Head/notebooks/hparamtuning.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m all_CLIP_scores \u001b[39m=\u001b[39m []\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bniessnerlab/home/schmid/Text2Head/notebooks/hparamtuning.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39mfor\u001b[39;00m prompt \u001b[39min\u001b[39;00m prompts:\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bniessnerlab/home/schmid/Text2Head/notebooks/hparamtuning.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=19'>20</a>\u001b[0m     _, best_score, _ \u001b[39m=\u001b[39m get_latent_from_text(prompt, hparams, init_lat\u001b[39m=\u001b[39;49mlat_mean)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bniessnerlab/home/schmid/Text2Head/notebooks/hparamtuning.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=20'>21</a>\u001b[0m     all_CLIP_scores\u001b[39m.\u001b[39mappend(best_score)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bniessnerlab/home/schmid/Text2Head/notebooks/hparamtuning.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=22'>23</a>\u001b[0m all_CLIP_scores_tensor \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mstack(all_CLIP_scores)\n",
      "File \u001b[0;32m~/Text2Head/utils/pipeline.py:141\u001b[0m, in \u001b[0;36mget_latent_from_text\u001b[0;34m(prompt, hparams, init_lat)\u001b[0m\n\u001b[1;32m    139\u001b[0m latents \u001b[39m=\u001b[39m []\n\u001b[1;32m    140\u001b[0m images \u001b[39m=\u001b[39m []\n\u001b[0;32m--> 141\u001b[0m best_score \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor([\u001b[39m0\u001b[39m])\n\u001b[1;32m    142\u001b[0m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mempty_cache()\n\u001b[1;32m    143\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m~/Text2Head/utils/pipeline.py:65\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(lat_rep, prompt, camera_params, phong_params, light_params)\u001b[0m\n\u001b[1;32m     62\u001b[0m     lat_std \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mfrom_numpy(np\u001b[39m.\u001b[39mload(env_paths\u001b[39m.\u001b[39mASSETS \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39mnphm_lat_std.npy\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[1;32m     63\u001b[0m     \u001b[39mreturn\u001b[39;00m lat_mean, lat_std\n\u001b[0;32m---> 65\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(lat_rep, prompt, camera_params, phong_params, light_params):\n\u001b[1;32m     66\u001b[0m     image \u001b[39m=\u001b[39m render(decoder_shape, lat_rep, camera_params, phong_params, light_params)\n\u001b[1;32m     68\u001b[0m     image_c_first \u001b[39m=\u001b[39m image\u001b[39m.\u001b[39mpermute(\u001b[39m2\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/Text2Head/utils/render.py:201\u001b[0m, in \u001b[0;36mrender\u001b[0;34m(model, lat_rep, camera_params, phong_params, light_params, mesh_path)\u001b[0m\n\u001b[1;32m    197\u001b[0m directions \u001b[39m=\u001b[39m (transposed_directions \u001b[39m/\u001b[39m transposed_directions\u001b[39m.\u001b[39mnorm(dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m))\u001b[39m.\u001b[39mT  \u001b[39m# [pu*pv, 3]\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m    200\u001b[0m \u001b[39m# Option 1: Use SDF\u001b[39;00m\n\u001b[0;32m--> 201\u001b[0m     hit_positions, hit_mask \u001b[39m=\u001b[39m two_phase_tracing(sdf, camera_position, directions, camera_params[\u001b[39m'\u001b[39;49m\u001b[39mmax_ray_length\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[1;32m    202\u001b[0m \u001b[39m# Option 2: Use Mesh\u001b[39;00m\n\u001b[1;32m    203\u001b[0m \u001b[39m# intersections, hit_mask, index_tri = mesh_trace(mesh_path, camera_position, directions)\u001b[39;00m\n\u001b[1;32m    204\u001b[0m \n\u001b[1;32m    205\u001b[0m \u001b[39m#with torch.no_grad():\u001b[39;00m\n\u001b[1;32m    206\u001b[0m \u001b[39m# Option 1: Use SDF\u001b[39;00m\n\u001b[1;32m    207\u001b[0m reflections \u001b[39m=\u001b[39m phong_model(sdf, hit_positions[hit_mask], camera_position, phong_params, light_params, mesh_path)\n",
      "File \u001b[0;32m~/Text2Head/utils/render.py:140\u001b[0m, in \u001b[0;36mtwo_phase_tracing\u001b[0;34m(sdf, camera_position, norm_directions, max_length, scale, eps)\u001b[0m\n\u001b[1;32m    138\u001b[0m N \u001b[39m=\u001b[39m norm_directions\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n\u001b[1;32m    139\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m--> 140\u001b[0m     hits_1, hit_mask_1, t_1 \u001b[39m=\u001b[39m acc_sphere_trace(sdf, camera_position, norm_directions, max_length,\n\u001b[1;32m    141\u001b[0m                                                             scale\u001b[39m=\u001b[39;49m\u001b[39m2.\u001b[39;49m, eps\u001b[39m=\u001b[39;49m\u001b[39m0.025\u001b[39;49m)\n\u001b[1;32m    142\u001b[0m hits_2, hit_mask_2, t_2 \u001b[39m=\u001b[39m acc_sphere_trace(sdf, hits_1[hit_mask_1], norm_directions[hit_mask_1], \u001b[39m3.\u001b[39m,\n\u001b[1;32m    143\u001b[0m                                                         scale\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39msqrt(\u001b[39m2.\u001b[39m), eps\u001b[39m=\u001b[39m\u001b[39m0.005\u001b[39m)\n\u001b[1;32m    145\u001b[0m hit_mask \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mzeros(N)\u001b[39m.\u001b[39mbool()\n",
      "File \u001b[0;32m~/Text2Head/utils/render.py:117\u001b[0m, in \u001b[0;36macc_sphere_trace\u001b[0;34m(sdf, init_position, norm_directions, max_length, scale, eps, init_t)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m    115\u001b[0m d_curr[mask] \u001b[39m=\u001b[39m r_curr[mask] \u001b[39m+\u001b[39m scale \u001b[39m*\u001b[39m r_curr[mask] \u001b[39m*\u001b[39m torch\u001b[39m.\u001b[39mnan_to_num(\n\u001b[1;32m    116\u001b[0m     (d_curr[mask] \u001b[39m-\u001b[39m r_last[mask] \u001b[39m+\u001b[39m r_curr[mask]) \u001b[39m/\u001b[39m (d_curr[mask] \u001b[39m+\u001b[39m r_last[mask] \u001b[39m-\u001b[39m r_curr[mask]))\n\u001b[0;32m--> 117\u001b[0m r_next[mask] \u001b[39m=\u001b[39m sdf(positions[mask] \u001b[39m+\u001b[39;49m ((t[mask] \u001b[39m+\u001b[39;49m d_curr[mask]) \u001b[39m*\u001b[39;49m norm_directions[mask]\u001b[39m.\u001b[39;49mT)\u001b[39m.\u001b[39;49mT)\n\u001b[1;32m    119\u001b[0m normal_tracing_mask \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mabs(d_curr[mask]) \u001b[39m>\u001b[39m torch\u001b[39m.\u001b[39mabs(r_curr[mask]) \u001b[39m+\u001b[39m torch\u001b[39m.\u001b[39mabs(r_next[mask])\n\u001b[1;32m    120\u001b[0m \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39many(normal_tracing_mask):\n",
      "File \u001b[0;32m~/Text2Head/utils/render.py:168\u001b[0m, in \u001b[0;36mrender.<locals>.sdf\u001b[0;34m(positions, max_number)\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mcat(distances, dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39msqueeze()\n\u001b[1;32m    167\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 168\u001b[0m     distance \u001b[39m=\u001b[39m model(nphm_input\u001b[39m.\u001b[39;49mto(device), lat_rep_in\u001b[39m.\u001b[39;49mto(device), \u001b[39mNone\u001b[39;49;00m)[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mto(\u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    169\u001b[0m     \u001b[39mreturn\u001b[39;00m distance\u001b[39m.\u001b[39msqueeze()\n",
      "File \u001b[0;32m~/miniconda3/envs/nphm/lib/python3.9/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Text2Head/NPHM/src/NPHM/models/EnsembledDeepSDF.py:257\u001b[0m, in \u001b[0;36mFastEnsembleDeepSDFMirrored.forward\u001b[0;34m(self, xyz, lat_rep, anchors_gt)\u001b[0m\n\u001b[1;32m    254\u001b[0m coords \u001b[39m=\u001b[39m coords\u001b[39m.\u001b[39mpermute(\u001b[39m2\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m3\u001b[39m) \u001b[39m# nkps x B x N x 3\u001b[39;00m\n\u001b[1;32m    255\u001b[0m cond \u001b[39m=\u001b[39m cond\u001b[39m.\u001b[39mpermute(\u001b[39m2\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m3\u001b[39m) \u001b[39m# nkps x B x N x (dim_glob + dim_loc)\u001b[39;00m\n\u001b[0;32m--> 257\u001b[0m sdf_pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mensembled_deep_sdf(coords, cond)\n\u001b[1;32m    259\u001b[0m \u001b[39m# hack, not sure if this is a good idea\u001b[39;00m\n\u001b[1;32m    260\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining:\n",
      "File \u001b[0;32m~/miniconda3/envs/nphm/lib/python3.9/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Text2Head/NPHM/src/NPHM/models/EnsembledDeepSDF.py:121\u001b[0m, in \u001b[0;36mEnsembledDeepSDF.forward\u001b[0;34m(self, xyz, lat_rep)\u001b[0m\n\u001b[1;32m    118\u001b[0m     x \u001b[39m=\u001b[39m lin(x)\n\u001b[1;32m    120\u001b[0m     \u001b[39mif\u001b[39;00m layer \u001b[39m<\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_layers \u001b[39m-\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[0;32m--> 121\u001b[0m         x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mactivation(x)\n\u001b[1;32m    123\u001b[0m \u001b[39m# un-merge dimensions\u001b[39;00m\n\u001b[1;32m    124\u001b[0m x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mreshape(A, B, nP, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/nphm/lib/python3.9/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/nphm/lib/python3.9/site-packages/torch/nn/modules/activation.py:841\u001b[0m, in \u001b[0;36mSoftplus.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    840\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 841\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49msoftplus(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbeta, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mthreshold)\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 440.00 MiB (GPU 0; 10.91 GiB total capacity; 8.29 GiB already allocated; 95.44 MiB free; 8.57 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    study = optuna.create_study(storage=\"sqlite:///../optuna_study_hparams.db\", study_name=\"optim_hparams\", direction='maximize', load_if_exists=True)\n",
    "    study.optimize(objective, n_trials=1)\n",
    "        \n",
    "    best_params = study.best_params\n",
    "    print(best_params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nphm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
