{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-04T17:26:46.968182Z",
     "start_time": "2023-12-04T17:26:31.487569Z"
    }
   },
   "outputs": [],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=0\n",
    "\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from torch.optim import Adam\n",
    "from utils.pipeline import forward, get_latent_mean_std, get_latent_from_text\n",
    "from utils.similarity import CLIP_similarity, DINO_similarity\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_mean, lat_std = get_latent_mean_std()\n",
    "lat_rep = (torch.randn(lat_mean.shape) * lat_std * 0.85 + lat_mean).detach().requires_grad_(True)\n",
    "\n",
    "hparams = {\n",
    "        'resolution': 120,\n",
    "        'n_iterations': 120,\n",
    "        'optimizer_lr': 2e-4,\n",
    "        'optimizer_weight_decay': 5e-5,\n",
    "        'lr_scheduler_factor': 0.53,\n",
    "        'lr_scheduler_patience': 5,\n",
    "        'lr_scheduler_min_lr': 2.6e-6\n",
    "    }\n",
    "\n",
    "best_latent, best_CLIP_score, best_prob_score, hist = get_latent_from_text(prompt, hparams, CLIP_gt=CLIP_gt, DINO_gt=DINO_gt)\n",
    "print('best_CLIP_score', best_CLIP_score)\n",
    "print('best_prob_score', best_prob_score)\n",
    "\n",
    "lat_rep = best_latent\n",
    "'''\n",
    "camera_params = {\n",
    "        \"camera_distance\": 1.42,\n",
    "        \"camera_angle\": 45.,\n",
    "        \"focal_length\": 3.15,\n",
    "        \"max_ray_length\": 3, #(0.5 + 1) * 3.15 + 1.5,\n",
    "        # Image\n",
    "        \"resolution_y\": 200,\n",
    "        \"resolution_x\": 200\n",
    "    }\n",
    "\n",
    "phong_params = {\n",
    "    \"ambient_coeff\": 0.67,\n",
    "    \"diffuse_coeff\": 0.79,\n",
    "    \"specular_coeff\": 0.3,  # 0.63,\n",
    "    \"shininess\": 1.,\n",
    "    # Colors\n",
    "    \"object_color\": torch.tensor([0.61, 0.61, 0.61]),  # torch.tensor([0.63, 0.17, 0.78]),\n",
    "    \"background_color\": torch.tensor([0., 0., 0.])  # torch.tensor([0.35, 0.94, 0.26])\n",
    "}\n",
    "\n",
    "light_params = {\n",
    "    \"amb_light_color\": torch.tensor([0.57, 0.5, 0.69]),\n",
    "    # light 1\n",
    "    \"light_intensity_1\": 1.,  # 1.1,\n",
    "    \"light_color_1\": torch.tensor([1., 1., 1.]),\n",
    "    \"light_dir_1\": torch.tensor([-0.41, -0.51, -0.76]),\n",
    "    # light p\n",
    "    \"light_intensity_p\": 0.,\n",
    "    \"light_color_p\": torch.tensor([0.88, 0.99, 0.74]),\n",
    "    \"light_pos_p\": torch.tensor([2., 0., 2.])\n",
    "}\n",
    "'''\n",
    "camera_params = {\n",
    "    \"camera_distance\": 0.21,\n",
    "    \"camera_angle\": 45.,\n",
    "    \"focal_length\": 2.57,\n",
    "    \"max_ray_length\": 3,\n",
    "    # Image\n",
    "    \"resolution_y\": hparams['resolution'],\n",
    "    \"resolution_x\": hparams['resolution']\n",
    "}\n",
    "phong_params = {\n",
    "    \"ambient_coeff\": 0.51,\n",
    "    \"diffuse_coeff\": 0.75,\n",
    "    \"specular_coeff\": 0.64,\n",
    "    \"shininess\": 0.5,\n",
    "    # Colors\n",
    "    \"object_color\": torch.tensor([0.53, 0.24, 0.64]),\n",
    "    \"background_color\": torch.tensor([0.36, 0.77, 0.29])\n",
    "}\n",
    "\n",
    "light_params = {\n",
    "    \"amb_light_color\": torch.tensor([0.9, 0.16, 0.55]),\n",
    "    # light 1\n",
    "    \"light_intensity_1\": 1.42,\n",
    "    \"light_color_1\": torch.tensor([0.8, 0.97, 0.89]),\n",
    "    \"light_dir_1\": torch.tensor([-0.6, -0.4, -0.67]),\n",
    "    # light p\n",
    "    \"light_intensity_p\": 0.62,\n",
    "    \"light_color_p\": torch.tensor([0.8, 0.97, 0.89]),\n",
    "    \"light_pos_p\": torch.tensor([1.19, -1.27, 2.24])\n",
    "}\n",
    "\n",
    "with torch.no_grad():\n",
    "    score_CLIP, score_prob, image = forward(lat_rep, \"untextured render of a face\", camera_params, phong_params, light_params)\n",
    "plt.imshow(image.detach().numpy())\n",
    "plt.axis('off')  # Turn off axes\n",
    "#plt.savefig(\"../optim_img/6\", bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-04T17:26:48.754399Z",
     "start_time": "2023-12-04T17:26:48.709693Z"
    }
   },
   "outputs": [],
   "source": [
    "lat_mean, lat_std = get_latent_mean_std()\n",
    "lat_rep = (torch.randn(lat_mean.shape) * lat_std * 0.85 + lat_mean).detach().requires_grad_(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-04T17:26:49.411931Z",
     "start_time": "2023-12-04T17:26:49.379419Z"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = Adam(params=[lat_rep],\n",
    "                 lr=0.001, \n",
    "                 maximize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-04T17:39:06.598585Z",
     "start_time": "2023-12-04T17:39:06.522400Z"
    }
   },
   "outputs": [],
   "source": [
    "camera_params = {\n",
    "        \"camera_distance\": 1.42,\n",
    "        \"camera_angle\": -55.,\n",
    "        \"focal_length\": 3.15,\n",
    "        \"max_ray_length\": 3, #(0.5 + 1) * 3.15 + 1.5,\n",
    "        # Image\n",
    "        \"resolution_y\": 200,\n",
    "        \"resolution_x\": 200\n",
    "    }\n",
    "\n",
    "phong_params = {\n",
    "    \"ambient_coeff\": 0.67,\n",
    "    \"diffuse_coeff\": 0.79,\n",
    "    \"specular_coeff\": 0.3,  # 0.63,\n",
    "    \"shininess\": 1.,\n",
    "    # Colors\n",
    "    \"object_color\": torch.tensor([0.61, 0.61, 0.61]),  # torch.tensor([0.63, 0.17, 0.78]),\n",
    "    \"background_color\": torch.tensor([0., 0., 0.])  # torch.tensor([0.35, 0.94, 0.26])\n",
    "}\n",
    "\n",
    "light_params = {\n",
    "    \"amb_light_color\": torch.tensor([0.57, 0.07, 0.69]),\n",
    "    # light 1\n",
    "    \"light_intensity_1\": 0.,  # 1.1,\n",
    "    \"light_color_1\": torch.tensor([0.88, 0.99, 0.74]),\n",
    "    \"light_dir_1\": torch.tensor([-0.41, -0.51, -0.76]),\n",
    "    # light p\n",
    "    \"light_intensity_p\": 1.,\n",
    "    \"light_color_p\": torch.tensor([0.88, 0.99, 0.74]),\n",
    "    \"light_pos_p\": torch.tensor([2., 0., 2.])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-04T17:41:26.028602Z",
     "start_time": "2023-12-04T17:39:08.011236Z"
    }
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    score_CLIP, score_prob, image = forward(lat_rep, \"untextured render of a face\", camera_params, phong_params, light_params)\n",
    "plt.imshow(image.detach().numpy())\n",
    "plt.axis('off')  # Turn off axes\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-04T17:45:05.085670Z",
     "start_time": "2023-12-04T17:42:34.071637Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "score[0].backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_latent = torch.load(\"../woman_latent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-04T17:30:14.678555Z",
     "start_time": "2023-12-04T17:29:14.530220Z"
    }
   },
   "outputs": [],
   "source": [
    "hparams = {\n",
    "        'resolution': 200,\n",
    "        'n_iterations': 160,\n",
    "        'optimizer_lr': 1.4e-3,\n",
    "        'lr_scheduler_factor': 0.9999999,\n",
    "        'lr_scheduler_patience': 7,\n",
    "        'lr_scheduler_min_lr': 2.6e-5\n",
    "    }\n",
    "\n",
    "#torch.cuda.memory._record_memory_history(True)\n",
    "best_latent, best_CLIP_score, best_prob_cscore, stats = get_latent_from_text(\"woman with shoulder long straight hair\", hparams)\n",
    "#torch.cuda.memory._record_memory_history(False)\n",
    "#torch.cuda.memory._dump_snapshot(\"../memory_snapshot.pickle\")\n",
    "#print(best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-04T17:32:05.779761Z",
     "start_time": "2023-12-04T17:32:04.932225Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(torch.tensor(hist[\"scores\"]).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-04T17:32:08.607684Z",
     "start_time": "2023-12-04T17:32:08.594915Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(latent, \"../woman_latent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "torch.save(torch.stack(hist[\"latents\"]), \"latent_history\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "torch.save(torch.stack(hist[\"images\"]), \"render_history\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-04T17:32:12.595200Z",
     "start_time": "2023-12-04T17:32:12.474059Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(hist[\"images\"][-1].detach().numpy())\n",
    "plt.axis('off')  # Turn off axes\n",
    "plt.show()\n",
    "#plt.savefig(f\"optim_img/high_lr_{i}\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-04T17:32:20.206671Z",
     "start_time": "2023-12-04T17:32:15.457577Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i, im in enumerate(hist[\"images\"]):\n",
    "    plt.imshow(im.detach().numpy())\n",
    "    plt.axis('off')  # Turn off axes\n",
    "    #plt.show()\n",
    "    plt.savefig(f\"../optim_img/{i}\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nphm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
