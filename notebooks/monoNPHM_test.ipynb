{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml, json\n",
    "import torch\n",
    "import os.path as osp\n",
    "\n",
    "from nphm_tum import env_paths as mono_env_paths\n",
    "from nphm_tum.models.neural3dmm import construct_n3dmm, load_checkpoint\n",
    "\n",
    "from NPHM import env_paths\n",
    "from NPHM.models.EnsembledDeepSDF import FastEnsembleDeepSDFMirrored\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from utils.render import render\n",
    "\n",
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../NPHM/scripts/configs/fitting_nphm.yaml', 'r') as f:\n",
    "    CFG = yaml.safe_load(f)\n",
    "        \n",
    "weight_dir_shape = env_paths.EXPERIMENT_DIR + '/{}/'.format(CFG['exp_name_shape'])\n",
    "fname_shape = weight_dir_shape + 'configs.yaml'\n",
    "with open(fname_shape, 'r') as f:\n",
    "    CFG_shape = yaml.safe_load(f)\n",
    "    \n",
    "lm_inds = np.load(env_paths.ANCHOR_INDICES_PATH)\n",
    "anchors = torch.from_numpy(np.load(env_paths.ANCHOR_MEAN_PATH)).float().unsqueeze(0).unsqueeze(0).to(device)\n",
    "decoder_shape = FastEnsembleDeepSDFMirrored(\n",
    "        lat_dim_glob=CFG_shape['decoder']['decoder_lat_dim_glob'],\n",
    "        lat_dim_loc=CFG_shape['decoder']['decoder_lat_dim_loc'],\n",
    "        hidden_dim=CFG_shape['decoder']['decoder_hidden_dim'],\n",
    "        n_loc=CFG_shape['decoder']['decoder_nloc'],\n",
    "        n_symm_pairs=CFG_shape['decoder']['decoder_nsymm_pairs'],\n",
    "        anchors=anchors,\n",
    "        n_layers=CFG_shape['decoder']['decoder_nlayers'],\n",
    "        pos_mlp_dim=CFG_shape['decoder'].get('pos_mlp_dim', 256),\n",
    "    )\n",
    "decoder_shape = decoder_shape.to(device)\n",
    "path = osp.join(weight_dir_shape, 'checkpoints/checkpoint_epoch_{}.tar'.format(CFG['checkpoint_shape']))\n",
    "model_checkpoint = torch.load(path, map_location=device)\n",
    "decoder_shape.load_state_dict(model_checkpoint['decoder_state_dict'], strict=True)\n",
    "\n",
    "def sdf(sdf_inputs, lat_rep):\n",
    "    lat_rep_in = torch.reshape(lat_rep[0], (1, 1, -1))\n",
    "    return decoder_shape(sdf_inputs, lat_rep_in, None)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_dir_shape = mono_env_paths.EXPERIMENT_DIR_REMOTE + '/'\n",
    "fname_shape = weight_dir_shape + 'configs.yaml'\n",
    "with open(fname_shape, 'r') as f:\n",
    "    CFG = yaml.safe_load(f)\n",
    "\n",
    "    # load participant IDs that were used for training\n",
    "    fname_subject_index = f\"{weight_dir_shape}/subject_train_index.json\"\n",
    "    with open(fname_subject_index, 'r') as f:\n",
    "        subject_index = json.load(f)\n",
    "\n",
    "    # load expression indices that were used for training\n",
    "    fname_subject_index = f\"{weight_dir_shape}/expression_train_index.json\"\n",
    "    with open(fname_subject_index, 'r') as f:\n",
    "        expression_index = json.load(f)\n",
    "\n",
    "\n",
    "    # construct the NPHM models and latent codebook\n",
    "    device = torch.device(\"cuda\")\n",
    "    neural_3dmm, latent_codes = construct_n3dmm(\n",
    "                                  cfg = CFG,\n",
    "                                  modalities=['geo', 'exp'],\n",
    "                                  n_latents=[len(subject_index), len(expression_index)],\n",
    "                                  device=device,\n",
    "                                  )\n",
    "\n",
    "    # load checkpoint from trained NPHM model, including the latent codes\n",
    "    ckpt_path = osp.join(weight_dir_shape, 'checkpoints/checkpoint_epoch_6500.tar')\n",
    "    load_checkpoint(ckpt_path, neural_3dmm, latent_codes)\n",
    "    \n",
    "    def mono_sdf(sdf_inputs, lat_rep):\n",
    "        dict_in = {\n",
    "            \"queries\":sdf_inputs\n",
    "        }\n",
    "        cond = {\n",
    "            \"geo\": torch.reshape(lat_rep[0], (1, 1, -1)),\n",
    "            \"exp\": torch.reshape(lat_rep[1], (1, 1, -1))\n",
    "        }\n",
    "        return neural_3dmm(dict_in, cond)[\"sdf\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_mean = latent_codes.codebook['geo'].embedding.weight.mean(dim=0)\n",
    "geo_std = latent_codes.codebook['geo'].embedding.weight.std(dim=0)\n",
    "exp_mean = latent_codes.codebook['exp'].embedding.weight.mean(dim=0)\n",
    "exp_std = latent_codes.codebook['exp'].embedding.weight.std(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_rep = torch.stack([geo_mean, exp_mean], axis=0)\n",
    "\n",
    "camera_params = {\n",
    "        \"camera_distance\": 0.21 * 2.57,\n",
    "        \"camera_angle\": 45.,\n",
    "        \"focal_length\": 2.57,\n",
    "        \"max_ray_length\": 3,\n",
    "        # Image\n",
    "        \"resolution_y\": 200,\n",
    "        \"resolution_x\": 200\n",
    "    }\n",
    "phong_params = {\n",
    "        \"ambient_coeff\": 0.51,\n",
    "        \"diffuse_coeff\": 0.75,\n",
    "        \"specular_coeff\": 0.64,\n",
    "        \"shininess\": 0.5,\n",
    "        # Colors\n",
    "        \"object_color\": torch.tensor([0.53, 0.24, 0.64]),\n",
    "        \"background_color\": torch.tensor([0.36, 0.77, 0.29])\n",
    "    }\n",
    "\n",
    "light_params = {\n",
    "        \"amb_light_color\": torch.tensor([0.9, 0.16, 0.55]),\n",
    "        # light 1\n",
    "        \"light_intensity_1\": 1.42,\n",
    "        \"light_color_1\": torch.tensor([0.8, 0.97, 0.89]),\n",
    "        \"light_dir_1\": torch.tensor([-0.6, -0.4, -0.67]),\n",
    "        # light p\n",
    "        \"light_intensity_p\": 0.62,\n",
    "        \"light_color_p\": torch.tensor([0.8, 0.97, 0.89]),\n",
    "        \"light_pos_p\": torch.tensor([1.19, -1.27, 2.24])\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_mean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_rep.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = render(sdf, lat_rep, camera_params, phong_params, light_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_dict = {\n",
    "    \"queries\":torch.zeros((1, 6, 3)).cuda()\n",
    "}\n",
    "\n",
    "cond = {\n",
    "    \"geo\": geo_mean,\n",
    "    \"exp\": exp_mean\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neural_3dmm(in_dict, cond)[\"sdf\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Text2Head",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
