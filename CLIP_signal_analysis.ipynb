{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T12:53:20.698803Z",
     "start_time": "2023-11-09T12:53:04.310216Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import clip\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model, preprocess = clip.load(\"ViT-B/32\", device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4159e9e7136f1674",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T12:45:43.698148Z",
     "start_time": "2023-11-09T12:45:39.035861Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# image inputs\n",
    "image_folder = '/Users/katharinaschmid/Text2Head/NPHM-main/rendering_data'\n",
    "\n",
    "images = []\n",
    "preprocessed_images = torch.tensor([])\n",
    "file_list = sorted(os.listdir(image_folder))\n",
    "\n",
    "keys = ['default', 'colors', 'shininess', 'light_front', '_mirror', 'antimirror', 'resolution', 'side', 'colorful']\n",
    "for key in keys:\n",
    "    print(key)\n",
    "    for filename in file_list:\n",
    "        if filename.endswith(key + \".png\"):\n",
    "            image = Image.open(os.path.join(image_folder, filename))\n",
    "            images.append(image)\n",
    "            preprocessed_image = preprocess(image).unsqueeze(0) # [1, 3, 224, 224]\n",
    "            preprocessed_images = torch.cat((preprocessed_images, preprocessed_image), dim=0)\n",
    "num_images = len(images)\n",
    "\n",
    "fig, axes = plt.subplots(len(keys), 4, figsize=(15, 25))\n",
    "for i, img in enumerate(images):\n",
    "    ax = axes[i//4, i%4]\n",
    "    ax.imshow(img)  # Display each image\n",
    "    ax.axis('off')  # Turn off axis labels\n",
    "\n",
    "plt.show()\n",
    "print(preprocessed_images.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4528ac01242dad4",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Individual Sensitivity of Parameters\n",
    "Result: In general, the tests \"colorful\" and \"antimirror\" performed better than default.\n",
    "A small increase in resolution doesn't lead to better results. All other tests lead to worse performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e3bdecf79683d0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T15:47:44.040751Z",
     "start_time": "2023-11-09T15:46:41.909855Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# text inputs\n",
    "general = \"An image of the bust of \"\n",
    "captions = []\n",
    "captions.append(general + \"a young man\")\n",
    "captions.append(general + \"an Asian young man\")\n",
    "captions.append(general + \"a young man with wide forehead\")\n",
    "captions.append(general + \"a young man with long, curly hair\")\n",
    "captions.append(general + \"a young man with a big nose\")\n",
    "captions.append(general + \"a chubby man\")\n",
    "captions.append(general + \"a woman\")\n",
    "\n",
    "\n",
    "preprocessed_text = clip.tokenize(captions).to(device) # [num_captions, 77]\n",
    "\n",
    "with torch.no_grad():\n",
    "    image_features = model.encode_image(preprocessed_images) # [num_images, 512]\n",
    "    text_features = model.encode_text(preprocessed_text) # [num_captions, 512]\n",
    "\n",
    "# Normalize\n",
    "image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "text_features /= text_features.norm(dim=-1, keepdim=True)\n",
    "\n",
    "cosine_similarity = torch.matmul(image_features, text_features.T)\n",
    "cosine_similarity = cosine_similarity.reshape(-1, 4, len(captions)) # [tests, images, captions]\n",
    "print(cosine_similarity.shape)\n",
    "\n",
    "num_tests = cosine_similarity.shape[0]\n",
    "print(num_tests)\n",
    "\n",
    "for c in range(len(captions)):\n",
    "    print('Test: ', captions[c])\n",
    "    sim_np = cosine_similarity[:, :, c].squeeze(-1).numpy()\n",
    "    row_labels = [keys[test] for test in range(num_tests)]\n",
    "    col_labels = [f\"Image_{i}\" for i in range(4)]\n",
    "    df = pd.DataFrame(sim_np, index=row_labels, columns=col_labels)\n",
    "    \n",
    "    # Let's analyze!\n",
    "    df['Max_Image'] = df.idxmax(axis=1, numeric_only=True)\n",
    "    df['Min_Image'] = df.idxmin(axis=1, numeric_only=True)\n",
    "    df['Max_Value'] = df.max(axis=1, numeric_only=True)\n",
    "    df['Min_Value'] = df.min(axis=1, numeric_only=True)\n",
    "    \n",
    "    df['Max_Delta'] = df['Max_Value'] - df['Min_Value']\n",
    "    df['Max_Ratio'] = df['Min_Value'] / df['Max_Value']\n",
    "    print(df)\n",
    "    \n",
    "    top_delta = df.nlargest(3, 'Max_Delta').index.tolist()\n",
    "    top_ratio = df.nsmallest(3, 'Max_Ratio').index.tolist()\n",
    "    print(\"Test names of the top 3 rows with highest Delta values:\", top_delta)\n",
    "    print(\"Test names of the top 3 rows with lowest Ratio values:\", top_delta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846eee523aefb705",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Influence of combining image features\n",
    "1) Combine all tests\n",
    "--> Leads to worse performance\n",
    "2) Combine top performing tests\n",
    "--> Leads to a slight improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76370f5ea8f170f7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T16:12:07.473706Z",
     "start_time": "2023-11-09T16:12:07.359982Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image_features_reshaped = image_features.reshape(-1, 4, 512)\n",
    "\n",
    "# Average over all tests\n",
    "image_features_avg = image_features_reshaped.sum(dim=0)\n",
    "image_features_avg = image_features_avg / image_features_avg.norm(dim=-1, keepdim=True)\n",
    "\n",
    "cosine_similarity_avg = torch.matmul(image_features_avg, text_features.T)\n",
    "print('Average over all tests')\n",
    "sim_avg_np = cosine_similarity_avg.T.numpy()\n",
    "row_labels = [f\"Caption_{i}\" for i in range(len(captions))] #[captions[test] for test in range(len(captions))]\n",
    "col_labels = [f\"Image_{i}\" for i in range(4)]\n",
    "df_avg = pd.DataFrame(sim_avg_np, index=row_labels, columns=col_labels)\n",
    "\n",
    "# Let's analyze!\n",
    "df_avg['Max_Image'] = df_avg.idxmax(axis=1, numeric_only=True)\n",
    "df_avg['Min_Image'] = df_avg.idxmin(axis=1, numeric_only=True)\n",
    "df_avg['Max_Value'] = df_avg.max(axis=1, numeric_only=True)\n",
    "df_avg['Min_Value'] = df_avg.min(axis=1, numeric_only=True)\n",
    "\n",
    "df_avg['Max_Delta'] = df_avg['Max_Value'] - df_avg['Min_Value']\n",
    "df_avg['Max_Ratio'] = df_avg['Min_Value'] / df_avg['Max_Value']\n",
    "print(df_avg)\n",
    "\n",
    "#############\n",
    "print('#########################')\n",
    "\n",
    "# Average over top tests\n",
    "image_features_top = torch.stack((image_features_reshaped[0, :, :], image_features_reshaped[5, :, :], image_features_reshaped[8, :, :]), dim=0)\n",
    "image_features_avg_top = image_features_top.sum(dim=0)\n",
    "image_features_avg_top = image_features_avg_top / image_features_avg_top.norm(dim=-1, keepdim=True)\n",
    "cosine_similarity_avg_top = torch.matmul(image_features_avg_top, text_features.T)\n",
    "print('Average over top tests')\n",
    "sim_avg_top_np = cosine_similarity_avg_top.T.numpy()\n",
    "row_labels = [f\"Caption_{i}\" for i in range(len(captions))] #[captions[test] for test in range(len(captions))]\n",
    "col_labels = [f\"Image_{i}\" for i in range(4)]\n",
    "df_avg_top = pd.DataFrame(sim_avg_top_np, index=row_labels, columns=col_labels)\n",
    "\n",
    "# Let's analyze!\n",
    "df_avg_top['Max_Image'] = df_avg_top.idxmax(axis=1, numeric_only=True)\n",
    "df_avg_top['Min_Image'] = df_avg_top.idxmin(axis=1, numeric_only=True)\n",
    "df_avg_top['Max_Value'] = df_avg_top.max(axis=1, numeric_only=True)\n",
    "df_avg_top['Min_Value'] = df_avg_top.min(axis=1, numeric_only=True)\n",
    "\n",
    "df_avg_top['Max_Delta'] = df_avg_top['Max_Value'] - df_avg_top['Min_Value']\n",
    "df_avg_top['Max_Ratio'] = df_avg_top['Min_Value'] / df_avg_top['Max_Value']\n",
    "print(df_avg_top)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628148de513bb790",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Delta analysis\n",
    "CLIP(img) - CLIP(avg_img) leads to a much stronger signal!\n",
    "--> antimirror + colorful better than default in all (7 and 6) cases\n",
    "--> light_front, resolution and _mirror better in 3, 3, 2 cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee29ec1aae32cdc3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T16:13:40.436349Z",
     "start_time": "2023-11-09T16:13:40.267149Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image_features_delta = image_features_reshaped[:, 1:, :] - image_features_reshaped[:, 0, :].unsqueeze(1)\n",
    "\n",
    "image_features_delta_norm = image_features_delta / image_features_delta.norm(dim=-1, keepdim=True)\n",
    "image_features_delta_norm = image_features_delta_norm.reshape(-1, 512)\n",
    "cosine_similarity_delta = torch.matmul(image_features_delta_norm, text_features.T)\n",
    "cosine_similarity_delta = cosine_similarity_delta.reshape(-1, 3, len(captions))\n",
    "\n",
    "for c in range(len(captions)):\n",
    "    print('Test: ', captions[c])\n",
    "    sim_delta_np = cosine_similarity_delta[:, :, c].squeeze(-1).numpy()\n",
    "    row_labels = [keys[test] for test in range(num_tests)]\n",
    "    col_labels = [f\"Image_{i}\" for i in range(3)]\n",
    "    df_delta = pd.DataFrame(sim_delta_np, index=row_labels, columns=col_labels)\n",
    "    \n",
    "    # Let's analyze!\n",
    "    df_delta['Max_Image'] = df_delta.idxmax(axis=1, numeric_only=True)\n",
    "    df_delta['Min_Image'] = df_delta.idxmin(axis=1, numeric_only=True)\n",
    "    df_delta['Max_Value'] = df_delta.max(axis=1, numeric_only=True)\n",
    "    df_delta['Min_Value'] = df_delta.min(axis=1, numeric_only=True)\n",
    "    \n",
    "    df_delta['Max_Delta'] = df_delta['Max_Value'] - df_delta['Min_Value']\n",
    "    df_delta['Max_Ratio'] = df_delta['Min_Value'] / df_delta['Max_Value']\n",
    "    print(df_delta)\n",
    "    \n",
    "    top_delta = df_delta.nlargest(3, 'Max_Delta').index.tolist()\n",
    "    top_ratio = df_delta.nsmallest(3, 'Max_Ratio').index.tolist()\n",
    "    print(\"Test names of the top 3 rows with highest Delta values:\", top_delta)\n",
    "    print(\"Test names of the top 3 rows with lowest Ratio values:\", top_delta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e38a0d543caa4152",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Text input reduced to difference in combination with Delta Analysis\n",
    "--> significantly worse performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a875cb1d3d19b511",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T16:39:48.559095Z",
     "start_time": "2023-11-09T16:39:46.244525Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "captions_diff = []\n",
    "captions_diff.append(\"young, male\")\n",
    "captions_diff.append(\"Asian young man\")\n",
    "captions_diff.append(\"young man with wide forehead\")\n",
    "captions_diff.append(\"young man with long, curly hair\")\n",
    "captions_diff.append(\"young man with big nose\")\n",
    "captions_diff.append(\"chubby man\")\n",
    "captions_diff.append(\"woman\")\n",
    "\n",
    "preprocessed_text_diff = clip.tokenize(captions_diff).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    text_features_diff = model.encode_text(preprocessed_text_diff) # [num_captions, 512]\n",
    "\n",
    "# Normalize\n",
    "text_features_diff /= text_features_diff.norm(dim=-1, keepdim=True)\n",
    "\n",
    "cosine_similarity_delta_diff = torch.matmul(image_features_delta_norm, text_features_diff.T)\n",
    "cosine_similarity_delta_diff = cosine_similarity_delta_diff.reshape(-1, 3, len(captions))\n",
    "\n",
    "for c in range(len(captions)):\n",
    "    print('Test: ', captions_diff[c])\n",
    "    sim_delta_diff_np = cosine_similarity_delta_diff[:, :, c].squeeze(-1).numpy()\n",
    "    row_labels = [keys[test] for test in range(num_tests)]\n",
    "    col_labels = [f\"Image_{i}\" for i in range(3)]\n",
    "    df_delta_diff = pd.DataFrame(sim_delta_diff_np, index=row_labels, columns=col_labels)\n",
    "    \n",
    "    # Let's analyze!\n",
    "    df_delta_diff['Max_Image'] = df_delta_diff.idxmax(axis=1, numeric_only=True)\n",
    "    df_delta_diff['Min_Image'] = df_delta_diff.idxmin(axis=1, numeric_only=True)\n",
    "    df_delta_diff['Max_Value'] = df_delta_diff.max(axis=1, numeric_only=True)\n",
    "    df_delta_diff['Min_Value'] = df_delta_diff.min(axis=1, numeric_only=True)\n",
    "    \n",
    "    df_delta_diff['Max_Delta'] = df_delta_diff['Max_Value'] - df_delta_diff['Min_Value']\n",
    "    df_delta_diff['Max_Ratio'] = df_delta_diff['Min_Value'] / df_delta_diff['Max_Value']\n",
    "    print(df_delta_diff)\n",
    "    \n",
    "    top_delta = df_delta_diff.nlargest(3, 'Max_Delta').index.tolist()\n",
    "    top_ratio = df_delta_diff.nsmallest(3, 'Max_Ratio').index.tolist()\n",
    "    print(\"Test names of the top 3 rows with highest Delta values:\", top_delta)\n",
    "    print(\"Test names of the top 3 rows with lowest Ratio values:\", top_delta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "931061429231ae74",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Delta Analysis + avg over promising tests\n",
    "--> performance better than default delta but worse than antimirror, colorful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d6db21fec31dca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T16:51:31.734054Z",
     "start_time": "2023-11-09T16:51:31.605112Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# default, antimirror, colorful\n",
    "image_features_delta_norm = image_features_delta / image_features_delta.norm(dim=-1, keepdim=True)\n",
    "\n",
    "image_features_top_delta = torch.stack((image_features_delta_norm[0, :, :], image_features_delta_norm[5, :, :], image_features_delta_norm[8, :, :]), dim=0)\n",
    "image_features_avg_top_delta = image_features_top_delta.sum(dim=0)\n",
    "image_features_avg_top_delta = image_features_avg_top_delta / image_features_avg_top_delta.norm(dim=-1, keepdim=True)\n",
    "\n",
    "cosine_similarity_avg_top_delta = torch.matmul(image_features_avg_top_delta, text_features.T)\n",
    "print('Average over top tests')\n",
    "sim_avg_top_delta_np = cosine_similarity_avg_top_delta.T.numpy()\n",
    "row_labels = [f\"Caption_{i}\" for i in range(len(captions))] #[captions[test] for test in range(len(captions))]\n",
    "col_labels = [f\"Image_{i}\" for i in range(3)]\n",
    "df_avg_top_delta = pd.DataFrame(sim_avg_top_delta_np, index=row_labels, columns=col_labels)\n",
    "\n",
    "# Let's analyze!\n",
    "df_avg_top_delta['Max_Image'] = df_avg_top_delta.idxmax(axis=1, numeric_only=True)\n",
    "df_avg_top_delta['Min_Image'] = df_avg_top_delta.idxmin(axis=1, numeric_only=True)\n",
    "df_avg_top_delta['Max_Value'] = df_avg_top_delta.max(axis=1, numeric_only=True)\n",
    "df_avg_top_delta['Min_Value'] = df_avg_top_delta.min(axis=1, numeric_only=True)\n",
    "\n",
    "df_avg_top_delta['Max_Delta'] = df_avg_top_delta['Max_Value'] - df_avg_top_delta['Min_Value']\n",
    "df_avg_top_delta['Max_Ratio'] = df_avg_top_delta['Min_Value'] / df_avg_top_delta['Max_Value']\n",
    "print(df_avg_top_delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e12420ae0b50182",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-09T15:48:03.936399Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# OLD CODE, NO USE FOR NOW\n",
    "\n",
    "fig, ax = plt2.subplots()\n",
    "im = ax.imshow(cosine_similarity, cmap='gray')\n",
    "\n",
    "# Show all ticks and label them with the respective list entries\n",
    "ax.set_xticks(np.arange(len(images)))\n",
    "ax.set_yticks(np.arange(len(captions)), labels=captions)\n",
    "\n",
    "# Rotate the tick labels and set their alignment.\n",
    "plt2.setp(ax.get_xticklabels(), ha=\"right\",\n",
    "         rotation_mode=\"anchor\")\n",
    "\n",
    "# Loop over data dimensions and create text annotations.\n",
    "for i in range(len(captions)):\n",
    "    for j in range(len(images)):\n",
    "        similarity = cosine_similarity[i, j].numpy()\n",
    "        formatted_similarity = \"{:.3f}\".format(similarity)  # Limit to 2 decimal places\n",
    "        text = ax.text(j, i, formatted_similarity,\n",
    "                       ha=\"center\", va=\"center\", color=\"r\")\n",
    "\n",
    "ax.set_title(\"Cosine Similarity\")\n",
    "fig.tight_layout()\n",
    "plt2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b0f215a71e0963",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
